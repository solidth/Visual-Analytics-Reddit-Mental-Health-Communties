{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib, sys\n",
    "from fnmatch import fnmatch\n",
    "from pathlib import Path\n",
    "import re\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Calculate Content Similarity based on the Average Submission for each Subreddit\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>word_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jrizos</td>\n",
       "      <td>1314204222</td>\n",
       "      <td>/r/addiction/comments/jt0n7/a_family_member_ha...</td>\n",
       "      <td>This person has been using for roughly 10 year...</td>\n",
       "      <td>addiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FlashGameAddict</td>\n",
       "      <td>1325584690</td>\n",
       "      <td>/r/addiction/comments/o0y5w/im_quitting_online...</td>\n",
       "      <td>I'm addicted to online games. Most recently I'...</td>\n",
       "      <td>addiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>themarknessmonster</td>\n",
       "      <td>1327220038</td>\n",
       "      <td>/r/addiction/comments/or9wd/is_it_possible_for...</td>\n",
       "      <td>I think I might be addicted to light, or, more...</td>\n",
       "      <td>addiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jmc726</td>\n",
       "      <td>1333120496</td>\n",
       "      <td>/r/addiction/comments/rl03q/tramodol_abuse_any...</td>\n",
       "      <td>For anyone not familiar with Tramadol, it's a ...</td>\n",
       "      <td>addiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PetiePal</td>\n",
       "      <td>1334264821</td>\n",
       "      <td>/r/addiction/comments/s6swk/my_friend_is_becom...</td>\n",
       "      <td>Hey guys. I've got a friend who recently came ...</td>\n",
       "      <td>addiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579814</th>\n",
       "      <td>throw_away_the_panda</td>\n",
       "      <td>1624366207</td>\n",
       "      <td>/r/SelfHate/comments/o5meab/i_genuinely_try_an...</td>\n",
       "      <td>I'm sat at my desk again and I'm unable to kee...</td>\n",
       "      <td>SelfHate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579815</th>\n",
       "      <td>twisted-spirit</td>\n",
       "      <td>1624495644</td>\n",
       "      <td>/r/SelfHate/comments/o6pzta/i_feel_like_i_dont...</td>\n",
       "      <td>The more I try to make friends, or pretend I'm...</td>\n",
       "      <td>SelfHate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579816</th>\n",
       "      <td>DedKulak1917</td>\n",
       "      <td>1624593084</td>\n",
       "      <td>/r/SelfHate/comments/o7ft41/really_not_a_fan_o...</td>\n",
       "      <td>Recently cheated on my fiancé. We are in the p...</td>\n",
       "      <td>SelfHate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579817</th>\n",
       "      <td>edensrotting</td>\n",
       "      <td>1624980579</td>\n",
       "      <td>/r/SelfHate/comments/oaall2/another_person_her...</td>\n",
       "      <td>I'm a self destructive person and honestly, i ...</td>\n",
       "      <td>SelfHate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579818</th>\n",
       "      <td>skyfallboy</td>\n",
       "      <td>1625073783</td>\n",
       "      <td>/r/SelfHate/comments/ob1zx7/thats_how_shame_le...</td>\n",
       "      <td>Somewhere along the way, most of us learned to...</td>\n",
       "      <td>SelfHate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344076 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       author  created_utc   \n",
       "0                      jrizos   1314204222  \\\n",
       "1             FlashGameAddict   1325584690   \n",
       "2          themarknessmonster   1327220038   \n",
       "3                      jmc726   1333120496   \n",
       "4                    PetiePal   1334264821   \n",
       "...                       ...          ...   \n",
       "1579814  throw_away_the_panda   1624366207   \n",
       "1579815        twisted-spirit   1624495644   \n",
       "1579816          DedKulak1917   1624593084   \n",
       "1579817          edensrotting   1624980579   \n",
       "1579818            skyfallboy   1625073783   \n",
       "\n",
       "                                                 permalink   \n",
       "0        /r/addiction/comments/jt0n7/a_family_member_ha...  \\\n",
       "1        /r/addiction/comments/o0y5w/im_quitting_online...   \n",
       "2        /r/addiction/comments/or9wd/is_it_possible_for...   \n",
       "3        /r/addiction/comments/rl03q/tramodol_abuse_any...   \n",
       "4        /r/addiction/comments/s6swk/my_friend_is_becom...   \n",
       "...                                                    ...   \n",
       "1579814  /r/SelfHate/comments/o5meab/i_genuinely_try_an...   \n",
       "1579815  /r/SelfHate/comments/o6pzta/i_feel_like_i_dont...   \n",
       "1579816  /r/SelfHate/comments/o7ft41/really_not_a_fan_o...   \n",
       "1579817  /r/SelfHate/comments/oaall2/another_person_her...   \n",
       "1579818  /r/SelfHate/comments/ob1zx7/thats_how_shame_le...   \n",
       "\n",
       "                                                  selftext  subreddit   \n",
       "0        This person has been using for roughly 10 year...  addiction  \\\n",
       "1        I'm addicted to online games. Most recently I'...  addiction   \n",
       "2        I think I might be addicted to light, or, more...  addiction   \n",
       "3        For anyone not familiar with Tramadol, it's a ...  addiction   \n",
       "4        Hey guys. I've got a friend who recently came ...  addiction   \n",
       "...                                                    ...        ...   \n",
       "1579814  I'm sat at my desk again and I'm unable to kee...   SelfHate   \n",
       "1579815  The more I try to make friends, or pretend I'm...   SelfHate   \n",
       "1579816  Recently cheated on my fiancé. We are in the p...   SelfHate   \n",
       "1579817  I'm a self destructive person and honestly, i ...   SelfHate   \n",
       "1579818  Somewhere along the way, most of us learned to...   SelfHate   \n",
       "\n",
       "         word_embedding  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "...                 ...  \n",
       "1579814             NaN  \n",
       "1579815             NaN  \n",
       "1579816             NaN  \n",
       "1579817             NaN  \n",
       "1579818             NaN  \n",
       "\n",
       "[344076 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../data/submissions_preprocessed.json')\n",
    "df['word_embedding'] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Now comparing:  addiction\n",
      "with: addiction\n",
      "Checkpoint: apply\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m source_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubreddit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m subreddit]\n\u001b[0;32m     18\u001b[0m target_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubreddit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m subreddit_to_compare]\n\u001b[1;32m---> 20\u001b[0m source_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msource_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromstring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m target_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m target_df\u001b[38;5;241m.\u001b[39mword_embedding\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mfromstring(x[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# String to Numpy Array\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4631\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4522\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4523\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4527\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4530\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4630\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     17\u001b[0m source_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubreddit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m subreddit]\n\u001b[0;32m     18\u001b[0m target_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubreddit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m subreddit_to_compare]\n\u001b[1;32m---> 20\u001b[0m source_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m source_df\u001b[38;5;241m.\u001b[39mword_embedding\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mfromstring(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     21\u001b[0m target_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m target_df\u001b[38;5;241m.\u001b[39mword_embedding\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mfromstring(x[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# String to Numpy Array\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_subreddits = list(df.subreddit.unique())\n",
    "columns = unique_subreddits\n",
    "content_similarity_matrix = pd.DataFrame(columns=columns)\n",
    "save_path = '../data/content_cosine_similarity_matrix.json'\n",
    "\n",
    "list_of_all_similarities = [] \n",
    "\n",
    "for subreddit in unique_subreddits:\n",
    "    similarities = []\n",
    "    for subreddit_to_compare in unique_subreddits:\n",
    "        print('\\n---\\nNow comparing: ', subreddit)\n",
    "        print('with: ' + subreddit_to_compare)\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        # Special Apply Method to extract the string\n",
    "        #\n",
    "        print('Checkpoint: apply')\n",
    "        source_df = df[df['subreddit'] == subreddit]\n",
    "        target_df = df[df['subreddit'] == subreddit_to_compare]\n",
    "\n",
    "        source_df['avg_embedding'] = source_df.word_embedding.apply(lambda x: np.fromstring(x[1:-1], sep=' '))\n",
    "        target_df['avg_embedding'] = target_df.word_embedding.apply(lambda x: np.fromstring(x[1:-1], sep=' '))\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        # String to Numpy Array\n",
    "        #\n",
    "        print('Checkpoint: to numpy')\n",
    "        source_temp = source_df['avg_embedding'].to_numpy()\n",
    "        target_temp = target_df['avg_embedding'].to_numpy()\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        # Numpy Array to List\n",
    "        #\n",
    "        print('Checkpoint: to list')\n",
    "        source_temp = source_temp.tolist()\n",
    "        target_temp = target_temp.tolist()\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        # Numpy Array to Tensor\n",
    "        #\n",
    "        print('Checkpoint: to tensor')\n",
    "        source_avg_embeddings = torch.Tensor(source_temp)\n",
    "        target_avg_embeddings = torch.Tensor(target_temp)\n",
    "        source_avg_embeddings = torch.mean(source_avg_embeddings, 1)\n",
    "        target_avg_embeddings = torch.mean(target_avg_embeddings, 1)\n",
    "        \n",
    "        # print('Checkpoint: to tensor')\n",
    "        # sub_tensors = torch.from_numpy(sub_temp)\n",
    "        # overlap_tensors = torch.from_numpy(overlap_temp)\n",
    "        \n",
    "        # Normalize\n",
    "        # print('Checkpoint: normalize')\n",
    "        # sub_tensors = torch.nn.functional.normalize(subreddit_avg_embeddings)\n",
    "        # overlap_tensors = torch.nn.functional.normalize(overlap_avg_embeddings)\n",
    "        \n",
    "        print('Checkpoint: to numpy')\n",
    "        a1 = source_avg_embeddings.numpy()\n",
    "        a2 = target_avg_embeddings.numpy()\n",
    "        \n",
    "        print(a1.shape)\n",
    "        # print(a2)\n",
    "        print(a2.shape)\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        if(len(a1) > len(a2)):\n",
    "            diff = len(a1) - len(a2)\n",
    "            print(\"Case 1\")\n",
    "            a2 = np.pad(a2, (0, len(a1) - len(a2)), 'constant')\n",
    "            # a2 = np.concatenate([a2, np.zeros(len(a1) - len(a2))])\n",
    "            # zeros = np.zeros((diff, 0))\n",
    "            # a2 = np.concatenate((a2[0], zeros))\n",
    "        else:\n",
    "            diff = len(a2) - len(a1)\n",
    "            print(\"Case 2\")\n",
    "            a1 = np.pad(a1, (0, len(a2) - len(a1)), 'constant')\n",
    "            # a1 = np.concatenate([a1, np.zeros(len(a2) - len(a1))])\n",
    "            # zeros = np.zeros((diff, 0))\n",
    "            # a1 = np.concatenate((a1[0], zeros))\n",
    "        \n",
    "        print(a1.shape)\n",
    "        print(a2.shape)\n",
    "        \n",
    "        # Back to Tensor\n",
    "        mean_embedding1 = torch.from_numpy(a1)\n",
    "        mean_embedding2 = torch.from_numpy(a2)\n",
    "        \n",
    "        # Compute cosine-similarities\n",
    "        cosine_scores = util.cos_sim(mean_embedding1, mean_embedding2)\n",
    "        # cosine_scores = cosine_similarity(mean_embedding1, mean_embedding2)\n",
    "        print(\"COSINE SCORE of the Average Embeddings:\")\n",
    "        print(cosine_scores)\n",
    "        similarities.append(cosine_scores)\n",
    "        print(\" Cosine Similarities\\n\", similarities)\n",
    "    list_of_all_similarities.append(similarities)\n",
    "cosine_matrix = pd.DataFrame(list_of_all_similarities, columns=unique_subreddits)\n",
    "cosine_matrix.index = unique_subreddits\n",
    "cosine_matrix.to_json(save_path)\n",
    "print(\"finished\")\n",
    "display(cosine_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
